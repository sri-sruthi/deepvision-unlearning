{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LM8-gR2bQhPG"
      },
      "outputs": [],
      "source": [
        "# Phase 2 Experiment Execution Notebook\n",
        "# DeepVision Unlearning Research Project\n",
        "# Authors: Krishna Midula K, Sri Sruthi M N\n",
        "# Purpose: Run baseline full training, unlearning experiments, and evaluation analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repo (if running in Colab)\n",
        "!rm -rf deepvision-unlearning\n",
        "!git clone https://github.com/sri-sruthi/deepvision-unlearning.git\n",
        "%cd deepvision-unlearning\n",
        "\n",
        "#Install Dependencies\n",
        "\n",
        "!pip install -r requirements.txt -q\n",
        "\n",
        "# Set repo path\n",
        "import sys\n",
        "sys.path.append('/content/deepvision-unlearning')\n",
        "\n",
        "# GPU Check\n",
        "import torch\n",
        "torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU Only\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "SyucbHihRDwE",
        "outputId": "d1576458-b8c9-4238-cb3a-c7e3111a8094"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepvision-unlearning'...\n",
            "remote: Enumerating objects: 249, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 249 (delta 2), reused 14 (delta 2), pack-reused 234 (from 1)\u001b[K\n",
            "Receiving objects: 100% (249/249), 39.65 MiB | 15.98 MiB/s, done.\n",
            "Resolving deltas: 100% (120/120), done.\n",
            "/content/deepvision-unlearning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Repo Structure Overview\n",
        "\n",
        "!apt install tree -q\n",
        "!tree -L 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRm_p4jrRJNT",
        "outputId": "fbb31f5b-f7d7-4c3e-9989-a86fd2898747"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 1s (53.5 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[01;34m.\u001b[0m\n",
            "├── \u001b[01;34mconfigs\u001b[0m\n",
            "│   └── \u001b[00mforget_sets.json\u001b[0m\n",
            "├── \u001b[01;34mdata\u001b[0m\n",
            "│   ├── \u001b[00mcifar_loaders.py\u001b[0m\n",
            "│   └── \u001b[00m__init__.py\u001b[0m\n",
            "├── \u001b[01;34mevaluation\u001b[0m\n",
            "│   ├── \u001b[00mconfusion.py\u001b[0m\n",
            "│   ├── \u001b[00membeddings.py\u001b[0m\n",
            "│   ├── \u001b[00m__init__.py\u001b[0m\n",
            "│   ├── \u001b[00mmetrics.py\u001b[0m\n",
            "│   ├── \u001b[00mmia_attack.py\u001b[0m\n",
            "│   ├── \u001b[00mruntime.py\u001b[0m\n",
            "│   └── \u001b[00mtsne_visualization.py\u001b[0m\n",
            "├── \u001b[01;34mexperiments\u001b[0m\n",
            "│   ├── \u001b[00m__init__.py\u001b[0m\n",
            "│   ├── \u001b[00mrun_evaluation.py\u001b[0m\n",
            "│   ├── \u001b[00mrun_scaling.py\u001b[0m\n",
            "│   ├── \u001b[00mrun_unlearning.py\u001b[0m\n",
            "│   └── \u001b[00mtrain.py\u001b[0m\n",
            "├── \u001b[01;34mforget_sets\u001b[0m\n",
            "│   ├── \u001b[00m__init__.py\u001b[0m\n",
            "│   └── \u001b[00mselector.py\u001b[0m\n",
            "├── \u001b[00m__init__.py\u001b[0m\n",
            "├── \u001b[01;34mlogs\u001b[0m\n",
            "├── \u001b[01;34mmodels\u001b[0m\n",
            "│   ├── \u001b[00m__init__.py\u001b[0m\n",
            "│   ├── \u001b[00mmobilenetv2.py\u001b[0m\n",
            "│   ├── \u001b[00mmobilevit.py\u001b[0m\n",
            "│   ├── \u001b[00mresnet18_cifar10_debug.pth\u001b[0m\n",
            "│   ├── \u001b[00mresnet18.py\u001b[0m\n",
            "│   └── \u001b[00mvit_tiny.py\u001b[0m\n",
            "├── \u001b[01;34mnotebooks\u001b[0m\n",
            "│   └── \u001b[00mphase1_debug.ipynb\u001b[0m\n",
            "├── \u001b[00mREADME.md\u001b[0m\n",
            "├── \u001b[00mrequirements.txt\u001b[0m\n",
            "├── \u001b[01;34munlearning_methods\u001b[0m\n",
            "│   ├── \u001b[00mgradient_ascent.py\u001b[0m\n",
            "│   ├── \u001b[00m__init__.py\u001b[0m\n",
            "│   └── \u001b[00msisa_unlearning.py\u001b[0m\n",
            "└── \u001b[01;34mutils\u001b[0m\n",
            "    ├── \u001b[00m__init__.py\u001b[0m\n",
            "    ├── \u001b[00mtrainer.py\u001b[0m\n",
            "    └── \u001b[00mtransforms.py\u001b[0m\n",
            "\n",
            "10 directories, 33 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Core Functions\n",
        "\n",
        "from models.resnet18 import get_resnet18\n",
        "from models.mobilenetv2 import get_mobilenetv2\n",
        "from models.vit_tiny import get_vit_tiny\n",
        "from models.mobilevit import get_mobilevit\n",
        "\n",
        "from data.cifar_loaders import get_cifar10_loaders\n",
        "from evaluation.metrics import forgetting_effectiveness, retention_accuracy"
      ],
      "metadata": {
        "id": "Q94e89jsRT0d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify Baseline Checkpoint\n",
        "\n",
        "!ls ./models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrmAYnmeRsNK",
        "outputId": "8250834f-286c-44c6-9d56-2d4235e81540"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__init__.py\tmobilevit.py  resnet18_cifar10_debug.pth  vit_tiny.py\n",
            "mobilenetv2.py\t__pycache__   resnet18.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Baseline Model\n",
        "\n",
        "!PYTHONPATH=/content/deepvision-unlearning python experiments/run_evaluation.py \\\n",
        "--model resnet18 --dataset cifar10 \\\n",
        "--model-path ./models/resnet18_cifar10_debug.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRz9xyB0Ry13",
        "outputId": "dbcca001-e2f3-42a8-d89e-e3a90519edfe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 170M/170M [00:13<00:00, 12.4MB/s]\n",
            "Forgetting Effectiveness: 0.70346\n",
            "Retention Accuracy: 71.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Command Examples\n",
        "\n",
        "# Full baseline training example\n",
        "# NOTE: Change model and epochs as needed\n",
        "\n",
        "print(\"Example baseline training command:\")\n",
        "print(\"\"\"\n",
        "!PYTHONPATH=/content/deepvision-unlearning python experiments/train.py \\\n",
        "--model resnet18 --dataset cifar10 --epochs 200 --batch_size 128\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5jb_Z7dcoo0",
        "outputId": "2f5acd9c-4b26-47e6-9dc1-901c88b6d1c0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example baseline training command:\n",
            "\n",
            "!PYTHONPATH=/content/deepvision-unlearning python experiments/train.py --model resnet18 --dataset cifar10 --epochs 200 --batch_size 128\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unlearning Command Examples\n",
        "\n",
        "print(\"Unlearning Example Commands:\")\n",
        "print(\"\"\"\n",
        "Sample-level forgetting:\n",
        "!PYTHONPATH=/content/deepvision-unlearning python experiments/run_unlearning.py \\\n",
        "--method ga --model resnet18 --dataset cifar10 --forget-type sample --forget-count 500\n",
        "\n",
        "Class-level forgetting:\n",
        "!PYTHONPATH=/content/deepvision-unlearning python experiments/run_unlearning.py \\\n",
        "--method ga --model resnet18 --dataset cifar10 --forget-type class --forget-class airplane\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXNymNnoc9Rn",
        "outputId": "c66bf7c2-252c-4bd7-a35c-c1a5306e1823"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unlearning Example Commands:\n",
            "\n",
            "Sample-level forgetting:\n",
            "!PYTHONPATH=/content/deepvision-unlearning python experiments/run_unlearning.py --method ga --model resnet18 --dataset cifar10 --forget-type sample --forget-count 500\n",
            "\n",
            "Class-level forgetting:\n",
            "!PYTHONPATH=/content/deepvision-unlearning python experiments/run_unlearning.py --method ga --model resnet18 --dataset cifar10 --forget-type class --forget-class airplane\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment Task List\n",
        "\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "md(\"\"\"\n",
        "### Phase 2 Responsibilities\n",
        "\n",
        "1. Train full baselines:\n",
        "    - ResNet18, MobileNetV2, ViT-Tiny, MobileViT\n",
        "2. Run unlearning experiments:\n",
        "    - Scaling: 100, 500, 1000, 2500, 5000 samples\n",
        "    - Class-level forgetting: airplane, cat, ship, dog, frog\n",
        "3. Compute & record:\n",
        "    - FE, RA, runtime, confusion drift\n",
        "4. Generate plots and tables\n",
        "5. Document findings in Results + Analysis section\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "k-VpzOkLdCs2",
        "outputId": "7210a3fc-9a34-4869-b380-a87906c3c55f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n### Phase 2 Responsibilities\n\n1. Train full baselines:\n    - ResNet18, MobileNetV2, ViT-Tiny, MobileViT\n2. Run unlearning experiments:\n    - Scaling: 100, 500, 1000, 2500, 5000 samples\n    - Class-level forgetting: airplane, cat, ship, dog, frog\n3. Compute & record:\n    - FE, RA, runtime, confusion drift\n4. Generate plots and tables\n5. Document findings in Results + Analysis section\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Results Storage Convention\n",
        "\n",
        "print(\"Store all results in /logs and /results\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVhPuXgEdPs0",
        "outputId": "ac0736b8-99a3-4287-b273-f079ec98ff53"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Store all results in /logs and /results\n"
          ]
        }
      ]
    }
  ]
}